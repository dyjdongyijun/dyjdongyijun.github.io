# jemdoc: menu{MENU}{index_research.html}
# The first line of this file is a special command that tells jemdoc which menu
# entry in the file named MENU to associate this page with.
= Research

Large models and enormous data are essential driven forces of the unprecedented successes achieved by modern algorithms, especially in scientific computing and machine learning. Nevertheless, the growing dimensionality and model complexity, as well as the non-negligible workload of data pre-processing, also bring formidable costs to such successes in both computation and data aggregation. As the deceleration of Moore's Law slackens the cost reduction of computation from the hardware level, *fast heuristics for expensive classical routines* and *efficient algorithms for exploiting limited data* are becoming increasingly indispensable for pushing the limit of algorithm potency. 

My research focuses on such efficient algorithms for fast execution and effective data utilization. 
- From the *computational efficiency* perspective, I work on designing and analyzing randomized low-rank decomposition algorithms that can be executed fast on large matrices.
    -- [https://arxiv.org/abs/2104.05877 Randomized pivoting-based CUR decompositions]
    -- [https://arxiv.org/abs/2211.04676 Canonical angles in randomized subspace approximations]
- From the *sample efficiency* perspective, I am interested in studying and improving the generalization and distributional robustness of learning algorithms in data-limited settings.
    -- [https://arxiv.org/abs/2202.12230 Sample efficiency of data augmentation consistency regularization]
    -- [https://arxiv.org/abs/2210.01891 Distributionally robust optimization under concept shift]


== Preprints
. *Yijun Dong*, Per-Gunnar Martinsson, Yuji Nakatsukasa. ``Efficient Bounds and Estimates for Canonical Angles in Randomized Subspace Approximations''. 2022. \[[https://arxiv.org/abs/2211.04676 arxiv]\]


== Publications
. *Yijun Dong*\*, Yuege Xie\*, Rachel Ward. ``Adaptively Weighted Data Augmentation Consistency Regularization for Robust Optimization under Concept Shift''. /International Conference on Machine Learning (ICML)/, 2023. \[[https://arxiv.org/abs/2210.01891 arxiv]\]
. Shuo Yang\*, *Yijun Dong*\*, Rachel Ward, Inderjit S Dhillon, Sujay Sanghavi, Qi Lei. ``Sample Efficiency of Data Augmentation Consistency Regularization''. /International Conference on Artificial Intelligence and Statistics (AISTATS)/, 2023. \[[https://arxiv.org/abs/2202.12230 arxiv], [https://proceedings.mlr.press/v206/yang23c.html pmlr]\]
. *Yijun Dong*, Per-Gunnar Martinsson. ``Simpler is better: A comparative study of randomized algorithms for computing the CUR decomposition''. /Advances in Computational Mathematics/, 2023. \[[https://arxiv.org/abs/2104.05877 arxiv]\]
. Chen Cheng\*, *Yijun Dong*\*, Matthew Dorian\*, Farhan Kamili\*, Effrosyni Seitaridou. ``Quantifying Biofilm Formation of /Sinorhizobium meliloti/ Bacterial Strains in Microfluidic Platforms by Measuring the Diffusion Coefficient of Polystyrene Beads''. /Open Journal of Biophysics/, 2017. \[[https://www.scirp.org/journal/paperinformation.aspx?paperid=77507 article]\]


== Selected Presentations
- Dissertation defense at Oden Institute, UT Austin (Austin, TX, 2023\/03\/29): ``Randomized Dimension Reduction with Statistical Guarantees''. \[[talks/2303_defense.pdf slides]\]


== Service
- Journal reviewer
    -- Calcolo (2023)
    -- BIT Numerical Mathematics (2022)
    -- IMA Journal of Numerical Analysis (2022)
    -- SIAM Journal on Matrix Analysis and Applications (2020)

- Conference reviewer
    -- AISTATS (2023)