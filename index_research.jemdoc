# jemdoc: menu{MENU}{index_research.html}
# The first line of this file is a special command that tells jemdoc which menu
# entry in the file named MENU to associate this page with.
= Research

Large models and enormous data are essential driven forces of the unprecedented successes achieved by modern algorithms, especially in scientific computing and machine learning. Nevertheless, the growing dimensionality and model complexity, as well as the non-negligible workload of data pre-processing, also bring formidable costs to such successes in both computation and data aggregation. As the deceleration of Moore's Law slackens the cost reduction of computation from the hardware level, fast heuristics for expensive classical routines and efficient algorithms for exploiting limited data are becoming increasingly indispensable for pushing the limit of algorithm potency. 

My research focuses on such efficient algorithms for fast execution and effective data utilization. 
- From the *computational efficiency* perspective, I work on designing and analyzing randomized low-rank decomposition algorithms that can be executed fast on large matrices.
    -- [https://link.springer.com/article/10.1007/s10444-023-10061-z Simpler is better: A comparative study of randomized algorithms for computing the CUR decomposition]
    -- [https://epubs.siam.org/doi/abs/10.1137/23M1584733 Efficient Bounds and Estimates for Canonical Angles in Randomized Subspace Approximations]
    -- [https://arxiv.org/abs/2309.16002 Robust Blockwise Random Pivoting: Fast and Accurate Adaptive Interpolative Decomposition]
- From the *sample efficiency* perspective, I am interested in studying and improving the generalization and distributional robustness of learning algorithms in data-limited settings.
    -- [https://proceedings.mlr.press/v206/yang23c.html Sample Efficiency of Data Augmentation Consistency Regularization]
    -- [https://proceedings.mlr.press/v202/dong23f.html Adaptively Weighted Data Augmentation Consistency Regularization for Robust Optimization under Concept Shift]
    -- [https://arxiv.org/abs/2307.11030 Cluster-aware Semi-supervised Learning: Relational Knowledge Distillation Provably Learns Clustering]
    -- [https://arxiv.org/abs/2407.06120 Sketchy Moment Matching: Toward Fast and Provable Data Selection for Finetuning]



== Selected Talks

- Talk at SIAM CSE25 minisymposium on ``Scientific Machine Learning for Stable Prediction of Dynamical Systems'': [talks/250305_RandomDynSys_CSE25.pdf Randomize instead of Regularize: Stable Time Integration for Poorly Conditioned Dynamical Systems]
- Talk at JMM 2025 ILAS Special Session on Randomness in Numerical Linear Algebra: [talks/250111_DataSelection_JMM.pdf Data Selection under Low Intrinsic Dimension: from Interpolatove Decomposition to Ridge Regression]
- Talk at University of Delaware Numerical Analysis and PDE Seminar: [talks/241031_DataSelection_UDelaware_NAPDE.pdf Toward Fast and Provable Data Selection under Low Intrinsic Dimension]
- Talk at SIAM PP24 minisymposium on Randomized Methods in Linear Solvers and Matrix Decompositions: [talks/240308_SIAM_PP24.pdf Robust Blockwise Random Pivoting: Fast and Accurate Adaptive Interpolative Decomposition]
- Talk at ICIAM 2023 minisymposium on Randomized Numerical Linear Algebra: [talks/230824_ICIAM_RandSubsapce.pdf Efficient Bounds and Estimates for Canonical Angles in Randomized Subspace Approximations]
- Dissertation defense at Oden Institute, UT Austin: [talks/2303_defense.pdf Randomized Dimension Reduction with Statistical Guarantees]



== Publications

Preprints
- [https://arxiv.org/abs/2502.05075 Discrepancies are Virtue: Weak-to-Strong Generalization through Lens of Intrinsic Dimension] \n 
Yijun Dong, Yicheng Li, Yunai Li, Jason D. Lee, Qi Lei \n
/Preprint/, 2025. 
\n


Conference Publications
- [https://arxiv.org/abs/2407.19126 Greedy Output Approximation: Towards Efficient Structured Pruning for LLMs Without Retraining] \n
Jianwei Li, Yijun Dong, Qi Lei \n 
/Conference on Parsimony and Learning (CPAL)/, 2025.
\n

- [https://arxiv.org/abs/2407.06120 Sketchy Moment Matching: Toward Fast and Provable Data Selection for Finetuning] \n
Yijun Dong\*, Hoang Phan\*, Xiang Pan\*, Qi Lei \n 
/Neural Information Processing Systems (NeurIPS)/, 2024. 
\[[https://github.com/Xiang-Pan/sketchy_moment_matching GitHub]\]
\n

- [https://arxiv.org/abs/2307.11030 Cluster-aware Semi-supervised Learning: Relational Knowledge Distillation Provably Learns Clustering]\n 
Yijun Dong\*, Kevin Miller\*, Qi Lei, Rachel Ward \n
/Neural Information Processing Systems (NeurIPS)/, 2023. 
\[[https://github.com/dyjdongyijun/Semi_Supervised_Knowledge_Distillation GitHub]\]
\n

- [https://arxiv.org/abs/2210.01891 Adaptively Weighted Data Augmentation Consistency Regularization for Robust Optimization under Concept Shift] \n
Yijun Dong\*, Yuege Xie\*, Rachel Ward \n
/International Conference on Machine Learning (ICML)/, 2023. 
\[[https://github.com/gail-yxie/adawac GitHub], [https://icml.cc/media/PosterPDFs/ICML%202023/23766.png?t=1688904573.564561 poster]\]
\n

- [https://proceedings.mlr.press/v206/yang23c.html Sample Efficiency of Data Augmentation Consistency Regularization] \n
Shuo Yang\*, Yijun Dong\*, Rachel Ward, Inderjit Dhillon, Sujay Sanghavi, Qi Lei \n
/International Conference on Artificial Intelligence and Statistics (AISTATS)/, 2023. 
\n


Journal Publications
- [https://arxiv.org/abs/2309.16002 Robust Blockwise Random Pivoting: Fast and Accurate Adaptive Interpolative Decomposition] \n
Yijun Dong, Chao Chen, Per-Gunnar Martinsson, Katherine Pearce \n 
/SIAM Journal on Matrix Analysis and Applications/, 2025. 
\[[https://github.com/dyjdongyijun/Robust_Blockwise_Random_Pivoting GitHub]\]
\n

- [https://arxiv.org/abs/2310.09417 Adaptive Parallelizable Algorithms for Interpolative Decompositions via Partially Pivoted LU] \n
Katherine J. Pearce, Chao Chen, Yijun Dong, Per-Gunnar Martinsson \n 
/Numerical Linear Algebra with Applications/, 2025.
\[[https://github.com/kjpearce/randLUPPadap GitHub]\] 
\n

- [https://epubs.siam.org/doi/abs/10.1137/23M1584733 Efficient Bounds and Estimates for Canonical Angles in Randomized Subspace Approximations] \n
Yijun Dong, Per-Gunnar Martinsson, Yuji Nakatsukasa \n
/SIAM Journal on Matrix Analysis and Applications/, 2024. 
\[[https://github.com/dyjdongyijun/Randomized_Subspace_Approximation GitHub]\]
\n

- [https://link.springer.com/article/10.1007/s10444-023-10061-z Simpler is better: A comparative study of randomized algorithms for computing the CUR decomposition] \n
Yijun Dong, Per-Gunnar Martinsson \n
/Advances in Computational Mathematics/, 2023.
\[[https://github.com/dyjdongyijun/Randomized_Pivoted_ID_CUR GitHub]\]
\n

- [https://www.scirp.org/journal/paperinformation.aspx?paperid=77507 Quantifying Biofilm Formation of /Sinorhizobium meliloti/ Bacterial Strains in Microfluidic Platforms by Measuring the Diffusion Coefficient of Polystyrene Beads] \n
Chen Cheng\*, Yijun Dong\*, Matthew Dorian\*, Farhan Kamili\*, Effrosyni Seitaridou \n
/Open Journal of Biophysics/, 2017. 
\n


Workshop Publications
- [https://openreview.net/pdf?id=WPvQVQrbch Randomly Pivoted V-optimal Design: Fast Data Selection under Low Intrinsic Dimension] \n 
Yijun Dong\*, Xiang Pan\*, Hoang Phan\*, Qi Lei \n 
/Workshop on Machine Learning and Compression, NeurIPS/, 2024.
\n

(* denotes equal contribution or alphabetical order)