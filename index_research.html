<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Research</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Home</div>
<div class="menu-item"><a href="index.html">About</a></div>
<div class="menu-item"><a href="index_research.html" class="current">Research</a></div>
<div class="menu-item"><a href="index_teach.html">Teaching</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Research</h1>
</div>
<p>Large models and enormous data are essential driven forces of the unprecedented successes achieved by modern algorithms, especially in scientific computing and machine learning. Nevertheless, the growing dimensionality and model complexity, as well as the non-negligible workload of data pre-processing, also bring formidable costs to such successes in both computation and data aggregation. As the deceleration of Moore's Law slackens the cost reduction of computation from the hardware level, fast heuristics for expensive classical routines and efficient algorithms for exploiting limited data are becoming increasingly indispensable for pushing the limit of algorithm potency. 
</p>
<p>My research focuses on such efficient algorithms for fast execution and effective data utilization. 
</p>
<ul>
<li><p>From the <b>computational efficiency</b> perspective, I work on designing and analyzing randomized low-rank decomposition algorithms that can be executed fast on large matrices.
</p>
<ul>
<li><p><a href="https://link.springer.com/article/10.1007/s10444-023-10061-z" target=&ldquo;blank&rdquo;>Simpler is better: A comparative study of randomized algorithms for computing the CUR decomposition</a>
</p>
</li>
<li><p><a href="https://epubs.siam.org/doi/abs/10.1137/23M1584733" target=&ldquo;blank&rdquo;>Efficient Bounds and Estimates for Canonical Angles in Randomized Subspace Approximations</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2309.16002" target=&ldquo;blank&rdquo;>Robust Blockwise Random Pivoting: Fast and Accurate Adaptive Interpolative Decomposition</a>
</p>
</li></ul>
</li>
<li><p>From the <b>sample efficiency</b> perspective, I am interested in studying and improving the generalization and distributional robustness of learning algorithms in data-limited settings.
</p>
<ul>
<li><p><a href="https://proceedings.mlr.press/v206/yang23c.html" target=&ldquo;blank&rdquo;>Sample Efficiency of Data Augmentation Consistency Regularization</a>
</p>
</li>
<li><p><a href="https://proceedings.mlr.press/v202/dong23f.html" target=&ldquo;blank&rdquo;>Adaptively Weighted Data Augmentation Consistency Regularization for Robust Optimization under Concept Shift</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2307.11030" target=&ldquo;blank&rdquo;>Cluster-aware Semi-supervised Learning: Relational Knowledge Distillation Provably Learns Clustering</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2407.06120" target=&ldquo;blank&rdquo;>Sketchy Moment Matching: Toward Fast and Provable Data Selection for Finetuning</a>
</p>
</li>
</ul>

</li>
</ul>
<h2>Selected Talks</h2>
<ul>
<li><p>Talk at Flatiron CCM ML Seminar: <a href="talks/250530_W2S_Flatiron.pdf" target=&ldquo;blank&rdquo;>Discrepancies are Virtue: Weak-to-Strong Generalization through Lens of Intrinsic Dimension</a>
</p>
</li>
<li><p>Talk at JMM 2025 ILAS Special Session on Randomness in Numerical Linear Algebra: <a href="talks/250111_DataSelection_JMM.pdf" target=&ldquo;blank&rdquo;>Data Selection under Low Intrinsic Dimension: from Interpolatove Decomposition to Ridge Regression</a>
</p>
</li>
<li><p>Talk at University of Delaware Numerical Analysis and PDE Seminar: <a href="talks/241031_DataSelection_UDelaware_NAPDE.pdf" target=&ldquo;blank&rdquo;>Toward Fast and Provable Data Selection under Low Intrinsic Dimension</a>
</p>
</li>
<li><p>Talk at SIAM PP24 minisymposium on Randomized Methods in Linear Solvers and Matrix Decompositions: <a href="talks/240308_SIAM_PP24.pdf" target=&ldquo;blank&rdquo;>Robust Blockwise Random Pivoting: Fast and Accurate Adaptive Interpolative Decomposition</a>
</p>
</li>
<li><p>Talk at ICIAM 2023 minisymposium on Randomized Numerical Linear Algebra: <a href="talks/230824_ICIAM_RandSubsapce.pdf" target=&ldquo;blank&rdquo;>Efficient Bounds and Estimates for Canonical Angles in Randomized Subspace Approximations</a>
</p>
</li>
<li><p>Dissertation defense at Oden Institute, UT Austin: <a href="talks/2303_defense.pdf" target=&ldquo;blank&rdquo;>Randomized Dimension Reduction with Statistical Guarantees</a>
</p>
</li>
</ul>
<h2>Publications</h2>
<p>Preprints
</p>
<p>Conference Publications
</p>
<ul>
<li><p><a href="https://arxiv.org/abs/2502.05075" target=&ldquo;blank&rdquo;>Discrepancies are Virtue: Weak-to-Strong Generalization through Lens of Intrinsic Dimension</a>. <br /> 
Yijun Dong, Yicheng Li, Yunai Li, Jason D. Lee, Qi Lei. <br />
ICML 2025. 
<br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2407.19126" target=&ldquo;blank&rdquo;>Greedy Output Approximation: Towards Efficient Structured Pruning for LLMs Without Retraining</a>. <br />
Jianwei Li, Yijun Dong, Qi Lei. <br /> 
CPAL 2025.
<br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2407.06120" target=&ldquo;blank&rdquo;>Sketchy Moment Matching: Toward Fast and Provable Data Selection for Finetuning</a>. <br />
Yijun Dong*, Hoang Phan*, Xiang Pan*, Qi Lei. <br /> 
NeurIPS 2024. 
[<a href="https://github.com/Xiang-Pan/sketchy_moment_matching" target=&ldquo;blank&rdquo;>GitHub</a>]
<br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2307.11030" target=&ldquo;blank&rdquo;>Cluster-aware Semi-supervised Learning: Relational Knowledge Distillation Provably Learns Clustering</a>. <br /> 
Yijun Dong*, Kevin Miller*, Qi Lei, Rachel Ward. <br />
NeurIPS 2023. 
[<a href="https://github.com/dyjdongyijun/Semi_Supervised_Knowledge_Distillation" target=&ldquo;blank&rdquo;>GitHub</a>]
<br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2210.01891" target=&ldquo;blank&rdquo;>Adaptively Weighted Data Augmentation Consistency Regularization for Robust Optimization under Concept Shift</a>. <br />
Yijun Dong*, Yuege Xie*, Rachel Ward. <br />
ICML 2023. 
[<a href="https://github.com/gail-yxie/adawac" target=&ldquo;blank&rdquo;>GitHub</a>, <a href="https://icml.cc/media/PosterPDFs/ICML%202023/23766.png?t=1688904573.564561" target=&ldquo;blank&rdquo;>poster</a>]
<br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://proceedings.mlr.press/v206/yang23c.html" target=&ldquo;blank&rdquo;>Sample Efficiency of Data Augmentation Consistency Regularization</a>. <br />
Shuo Yang*, Yijun Dong*, Rachel Ward, Inderjit Dhillon, Sujay Sanghavi, Qi Lei. <br />
AISTATS 2023. 
<br />
</p>
</li>
</ul>
<p>Journal Publications
</p>
<ul>
<li><p><a href="https://arxiv.org/abs/2309.16002" target=&ldquo;blank&rdquo;>Robust Blockwise Random Pivoting: Fast and Accurate Adaptive Interpolative Decomposition</a>. <br />
Yijun Dong, Chao Chen, Per-Gunnar Martinsson, Katherine Pearce. <br /> 
SIAM Journal on Matrix Analysis and Applications 2025. 
[<a href="https://github.com/dyjdongyijun/Robust_Blockwise_Random_Pivoting" target=&ldquo;blank&rdquo;>GitHub</a>]
<br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2310.09417" target=&ldquo;blank&rdquo;>Adaptive Parallelizable Algorithms for Interpolative Decompositions via Partially Pivoted LU</a>. <br />
Katherine J. Pearce, Chao Chen, Yijun Dong, Per-Gunnar Martinsson. <br /> 
Numerical Linear Algebra with Applications 2025.
[<a href="https://github.com/kjpearce/randLUPPadap" target=&ldquo;blank&rdquo;>GitHub</a>] 
<br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://epubs.siam.org/doi/abs/10.1137/23M1584733" target=&ldquo;blank&rdquo;>Efficient Bounds and Estimates for Canonical Angles in Randomized Subspace Approximations</a>. <br />
Yijun Dong, Per-Gunnar Martinsson, Yuji Nakatsukasa. <br />
SIAM Journal on Matrix Analysis and Applications 2024. 
[<a href="https://github.com/dyjdongyijun/Randomized_Subspace_Approximation" target=&ldquo;blank&rdquo;>GitHub</a>]
<br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://link.springer.com/article/10.1007/s10444-023-10061-z" target=&ldquo;blank&rdquo;>Simpler is better: A comparative study of randomized algorithms for computing the CUR decomposition</a>. <br />
Yijun Dong, Per-Gunnar Martinsson. <br />
Advances in Computational Mathematics 2023.
[<a href="https://github.com/dyjdongyijun/Randomized_Pivoted_ID_CUR" target=&ldquo;blank&rdquo;>GitHub</a>]
<br />
</p>
</li>
</ul>
<ul>
<li><p><a href="https://www.scirp.org/journal/paperinformation.aspx?paperid=77507" target=&ldquo;blank&rdquo;>Quantifying Biofilm Formation of <i>Sinorhizobium meliloti</i> Bacterial Strains in Microfluidic Platforms by Measuring the Diffusion Coefficient of Polystyrene Beads</a>. <br />
Chen Cheng*, Yijun Dong*, Matthew Dorian*, Farhan Kamili*, Effrosyni Seitaridou. <br />
Open Journal of Biophysics 2017. 
<br />
</p>
</li>
</ul>
<p>Workshop Publications
</p>
<ul>
<li><p><a href="https://openreview.net/pdf?id=WPvQVQrbch" target=&ldquo;blank&rdquo;>Randomly Pivoted V-optimal Design: Fast Data Selection under Low Intrinsic Dimension</a>. <br /> 
Yijun Dong*, Xiang Pan*, Hoang Phan*, Qi Lei. <br /> 
Workshop on Machine Learning and Compression @ NeurIPS 2024.
<br />
</p>
</li>
</ul>
<p>(* denotes equal contribution or alphabetical order)</p>
<div id="footer">
<div id="footer-text">
Page generated 2025-06-01, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
<!-- Begin Web-Stat code v 7.0 -->
<span id="wts2115635"></span>
<script>var wts=document.createElement('script');wts.async=true;
wts.src='https://app.ardalio.com/log7.js';document.head.appendChild(wts);
wts.onload = function(){ wtslog7(2115635,3); };
</script><noscript><a href="https://www.web-stat.com">
<img src="https://app.ardalio.com/7/3/2115635.png"
alt="Web-Stat site stats"></a></noscript>
<!-- End Web-Stat code v 7.0 -->
</body>
</html>
