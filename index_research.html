<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Research</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Research</h1>
</div>
<p>Large models and enormous data are essential driven forces of the unprecedented successes achieved by modern algorithms, especially in scientific computing and machine learning. Nevertheless, the growing dimensionality and model complexity, as well as the non-negligible workload of data pre-processing, also bring formidable costs to such successes in both computation and data aggregation. As the deceleration of Moore's Law slackens the cost reduction of computation from the hardware level, <b>fast heuristics for expensive classical routines</b> and <b>efficient algorithms for exploiting limited data</b> are becoming increasingly indispensable for pushing the limit of algorithm potency. 
</p>
<p>My research focuses on such efficient algorithms for fast execution and effective data utilization. 
</p>
<ul>
<li><p>From the <b>computational efficiency</b> perspective, I work on designing and analyzing randomized low-rank decomposition algorithms that can be executed fast on large matrices.
</p>
<ul>
<li><p><a href="https://arxiv.org/abs/2104.05877" target=&ldquo;blank&rdquo;>Randomized pivoting-based CUR decompositions</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2211.04676" target=&ldquo;blank&rdquo;>Canonical angles in randomized subspace approximations</a>
</p>
</li></ul>
</li>
<li><p>From the <b>sample efficiency</b> perspective, I am interested in studying and improving the generalization and distributional robustness of learning algorithms in data-limited settings.
</p>
<ul>
<li><p><a href="https://arxiv.org/abs/2202.12230" target=&ldquo;blank&rdquo;>Sample efficiency of data augmentation consistency regularization</a>
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2210.01891" target=&ldquo;blank&rdquo;>Distributionally robust optimization under concept shift</a>
</p>
</li>
</ul>

</li>
</ul>
<h2>Preprints</h2>
<ol>
<li><p><b>Yijun Dong</b>, Per-Gunnar Martinsson, Yuji Nakatsukasa. &lsquo;&lsquo;Efficient Bounds and Estimates for Canonical Angles in Randomized Subspace Approximations&rsquo;&rsquo;. 2022. [<a href="https://arxiv.org/abs/2211.04676" target=&ldquo;blank&rdquo;>arxiv</a>]
</p>
</li>
</ol>
<h2>Publications</h2>
<ol>
<li><p><b>Yijun Dong</b>*, Yuege Xie*, Rachel Ward. &lsquo;&lsquo;Adaptively Weighted Data Augmentation Consistency Regularization for Robust Optimization under Concept Shift&rsquo;&rsquo;. <i>International Conference on Machine Learning (ICML)</i>, 2023. [<a href="https://arxiv.org/abs/2210.01891" target=&ldquo;blank&rdquo;>arxiv</a>]
</p>
</li>
<li><p>Shuo Yang*, <b>Yijun Dong</b>*, Rachel Ward, Inderjit S Dhillon, Sujay Sanghavi, Qi Lei. &lsquo;&lsquo;Sample Efficiency of Data Augmentation Consistency Regularization&rsquo;&rsquo;. <i>International Conference on Artificial Intelligence and Statistics (AISTATS)</i>, 2023. [<a href="https://arxiv.org/abs/2202.12230" target=&ldquo;blank&rdquo;>arxiv</a>, <a href="https://proceedings.mlr.press/v206/yang23c.html" target=&ldquo;blank&rdquo;>pmlr</a>]
</p>
</li>
<li><p><b>Yijun Dong</b>, Per-Gunnar Martinsson. &lsquo;&lsquo;Simpler is better: A comparative study of randomized algorithms for computing the CUR decomposition&rsquo;&rsquo;. <i>Advances in Computational Mathematics</i>, 2023. [<a href="https://arxiv.org/abs/2104.05877" target=&ldquo;blank&rdquo;>arxiv</a>]
</p>
</li>
<li><p>Chen Cheng*, <b>Yijun Dong</b>*, Matthew Dorian*, Farhan Kamili*, Effrosyni Seitaridou. &lsquo;&lsquo;Quantifying Biofilm Formation of <i>Sinorhizobium meliloti</i> Bacterial Strains in Microfluidic Platforms by Measuring the Diffusion Coefficient of Polystyrene Beads&rsquo;&rsquo;. <i>Open Journal of Biophysics</i>, 2017. [<a href="https://www.scirp.org/journal/paperinformation.aspx?paperid=77507" target=&ldquo;blank&rdquo;>article</a>]
</p>
</li>
</ol>
<h2>Selected Presentations</h2>
<ul>
<li><p>Dissertation defense at Oden Institute, UT Austin (Austin, TX, 2023/03/29): &lsquo;&lsquo;Randomized Dimension Reduction with Statistical Guarantees&rsquo;&rsquo;. [<a href="talks/2303_defense.pdf" target=&ldquo;blank&rdquo;>slides</a>]
</p>
</li>
</ul>
<h2>Service</h2>
<ul>
<li><p>Journal reviewer
</p>
<ul>
<li><p>Calcolo (2023)
</p>
</li>
<li><p>BIT Numerical Mathematics (2022)
</p>
</li>
<li><p>IMA Journal of Numerical Analysis (2022)
</p>
</li>
<li><p>SIAM Journal on Matrix Analysis and Applications (2020)
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>Conference reviewer
</p>
<ul>
<li><p>AISTATS (2023)</p>
</li>
</ul>

</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2023-05-27, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</div>
<!-- Begin Web-Stat code v 7.0 -->
<span id="wts2115635"></span>
<script>var wts=document.createElement('script');wts.async=true;
wts.src='https://app.ardalio.com/log7.js';document.head.appendChild(wts);
wts.onload = function(){ wtslog7(2115635,3); };
</script><noscript><a href="https://www.web-stat.com">
<img src="https://app.ardalio.com/7/3/2115635.png"
alt="Web-Stat site stats"></a></noscript>
<!-- End Web-Stat code v 7.0 -->
</body>
</html>
