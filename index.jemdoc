# jemdoc: menu{MENU}{index.html}
# The first line of this file is a special command that tells jemdoc which menu
# entry in the file named MENU to associate this page with.
= Yijun Dong (董一珺)

~~~
{}{img_left}{profile_pic.jpeg}{alt text}{150}{150}{https://dyjdongyijun.github.io}
Courant Instructor\/Assistant Professor (postdoc)\n
[https://cims.nyu.edu/dynamic/ Courant Institute of Mathematical Sciences]\n
[https://www.nyu.edu/ New York University]\n
Email: yd1319 \[@\] nyu \[DOT\] edu\n
Office: WWH 526, 251 Mercer St, New York, NY 10012
~~~


== About Me
I am a Courant Instructor\/Assistant Professor (postdoc) at the [https://cims.nyu.edu/dynamic/ Courant Institute] of [https://www.nyu.edu/ New York University] since 2023. I completed my PhD at the [https://www.oden.utexas.edu/ Oden Institute] of [https://www.utexas.edu/ UT Austin], advised by [https://users.oden.utexas.edu/~pgm/ Prof. Per-Gunnar Martinsson] and [https://sites.google.com/prod/view/rward Prof. Rachel Ward]. 

My research lies in *randomized numerical linear algebra* and *learning theory*. Specifically, I am interested in the computational and sample efficiency of algorithms in machine learning and scientific computing. From the computational efficiency perspective, my work is centered on matrix sketching and randomized low-rank decompositions like SVD and CUR. From the sample efficiency perspective, my work focuses on the generalization and distributional robustness of learning algorithms in data-limited settings.

([cv.pdf Curriculum Vitae], [https://scholar.google.com/citations?user=l3bmbCkAAAAJ&hl=en&oi=ao/ Google Scholar], [https://github.com/dyjdongyijun GitHub])


== News
- 2024\/06: Our paper got accepted at SIAM Journal on Matrix Analysis and Applications: [https://arxiv.org/abs/2211.04676 Efficient Bounds and Estimates for Canonical Angles in Randomized Subspace Approximations] with Per-Gunnar Martinsson, Yuji Nakatsukasa.
- 2023\/09: Our paper got accepted at NeurIPS 2023: [https://arxiv.org/abs/2307.11030 Cluster-aware Semi-supervised Learning: Relational Knowledge Distillation Provably Learns Clustering] with Kevin Miller, Qi Lei, Rachel Ward.
- 2023\/04: Our paper got accepted at ICML 2023: [https://arxiv.org/abs/2210.01891 Adaptively Weighted Data Augmentation Consistency Regularization for Robust Optimization under Concept Shift] with Yuege Xie, Rachel Ward.
- 2023\/03: I defended my thesis on ``Randomized Dimension Reduction with Statistical Guarantees'' at UT Austin. \[[https://arxiv.org/abs/2310.01739 dissertation], [talks/2303_defense.pdf slides]\]


== Recent Works
(* Equal contribution)
. [https://arxiv.org/abs/2309.16002 Robust Blockwise Random Pivoting: Fast and Accurate Adaptive Interpolative Decomposition] \n
Yijun Dong, Chao Chen, Per-Gunnar Martinsson, Katherine Pearce. 2023. \[[https://github.com/dyjdongyijun/Robust_Blockwise_Random_Pivoting GitHub]\]
\n
. [https://arxiv.org/abs/2211.04676 Efficient Bounds and Estimates for Canonical Angles in Randomized Subspace Approximations]. \n
Yijun Dong, Per-Gunnar Martinsson, Yuji Nakatsukasa. \n
/SIAM Journal on Matrix Analysis and Applications/, 2024. 
\[[https://github.com/dyjdongyijun/Randomized_Subspace_Approximation GitHub]\]
\n
. [https://arxiv.org/abs/2307.11030 Cluster-aware Semi-supervised Learning: Relational Knowledge Distillation Provably Learns Clustering].\n 
Yijun Dong\*, Kevin Miller\*, Qi Lei, Rachel Ward. \n
/Neural Information Processing Systems (NeurIPS)/, 2023. 
\[[https://github.com/dyjdongyijun/Semi_Supervised_Knowledge_Distillation GitHub]\]
\n
. [https://arxiv.org/abs/2210.01891 Adaptively Weighted Data Augmentation Consistency Regularization for Robust Optimization under Concept Shift]. \n
Yijun Dong\*, Yuege Xie\*, Rachel Ward. \n
/International Conference on Machine Learning (ICML)/, 2023. 
\[[https://github.com/gail-yxie/adawac GitHub], [https://icml.cc/media/PosterPDFs/ICML%202023/23766.png?t=1688904573.564561 poster]\]
\n
. [https://arxiv.org/abs/2202.12230 Sample Efficiency of Data Augmentation Consistency Regularization]. \n
Shuo Yang\*, Yijun Dong\*, Rachel Ward, Inderjit Dhillon, Sujay Sanghavi, Qi Lei. \n
/International Conference on Artificial Intelligence and Statistics (AISTATS)/, 2023. 
\[[https://proceedings.mlr.press/v206/yang23c.html pmlr]\]
\n
. [https://link.springer.com/article/10.1007/s10444-023-10061-z Simpler is better: A comparative study of randomized algorithms for computing the CUR decomposition]. \n
Yijun Dong, Per-Gunnar Martinsson. \n
/Advances in Computational Mathematics/, 2023.
\[[https://github.com/dyjdongyijun/Randomized_Pivoted_ID_CUR GitHub]\]
\n


== Education
Ph.D. in Computational Science, Engineering, and Mathematics, 2018 - 2023 \n
[https://www.oden.utexas.edu/ Oden Institute for Computational Engineering and Sciences], [https://www.utexas.edu/ UT Austin], Austin, Texas, US \n
Thesis: [notes/thesis_ut_2308.pdf Randomized Dimension Reduction with Statistical Guarantees] 

B.S. in Applied Mathematics & Engineering Science, 2014 - 2018 \n
[https://www.emory.edu/home/index.html Emory University], Atlanta, Georgia, US \n
Thesis: [https://etd.library.emory.edu/concern/etds/s1784k73d?locale=zh Crystals and Liquids in Gravitationally Confined Quasi-2-Dimensional Colloidal Systems]